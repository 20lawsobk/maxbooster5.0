import { schedule } from 'node-cron';
import logger from '../../server/logger.js';

interface BurnInMetrics {
  startTime: Date;
  totalRequests: number;
  successfulRequests: number;
  failedRequests: number;
  queueHealthChecks: number;
  aiModelChecks: number;
  systemHealthChecks: number;
  errors: Array<{ timestamp: Date; error: string }>;
  memorySnapshots: Array<{ timestamp: Date; heapUsed: number; rss: number }>;
  queueMetrics: Array<{ timestamp: Date; redisLatency: number; waiting: number; failed: number }>;
}

class BurnInTest {
  private metrics: BurnInMetrics;
  private isRunning = false;
  private baseUrl = 'http://localhost:5000';
  private intervalMinutes = 5;

  constructor() {
    this.metrics = {
      startTime: new Date(),
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      queueHealthChecks: 0,
      aiModelChecks: 0,
      systemHealthChecks: 0,
      errors: [],
      memorySnapshots: [],
      queueMetrics: [],
    };
  }

  async makeRequest(url: string, description: string): Promise<boolean> {
    this.metrics.totalRequests++;
    try {
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      this.metrics.successfulRequests++;
      logger.info(`âœ… Burn-in test: ${description} - OK`);
      return true;
    } catch (error) {
      this.metrics.failedRequests++;
      const errorMsg = `${description}: ${error instanceof Error ? error.message : 'Unknown error'}`;
      this.metrics.errors.push({ timestamp: new Date(), error: errorMsg });
      logger.error(`âŒ Burn-in test: ${errorMsg}`);
      return false;
    }
  }

  async checkQueueHealth(): Promise<void> {
    this.metrics.queueHealthChecks++;
    const success = await this.makeRequest(
      `${this.baseUrl}/api/monitoring/queue-health`,
      'Queue Health Check'
    );

    if (success) {
      try {
        const response = await fetch(`${this.baseUrl}/api/monitoring/queue-metrics`);
        const data = await response.json();
        if (data.metrics && data.metrics.length > 0) {
          const queueData = data.metrics[0];
          this.metrics.queueMetrics.push({
            timestamp: new Date(),
            redisLatency: queueData.redisLatency || 0,
            waiting: queueData.waiting || 0,
            failed: queueData.failed || 0,
          });
        }
      } catch (error) {
        logger.warn('Failed to capture queue metrics detail');
      }
    }
  }

  async checkAIModels(): Promise<void> {
    this.metrics.aiModelChecks++;
    await this.makeRequest(
      `${this.baseUrl}/api/monitoring/ai-models`,
      'AI Model Telemetry Check'
    );
  }

  async checkSystemHealth(): Promise<void> {
    this.metrics.systemHealthChecks++;
    await this.makeRequest(
      `${this.baseUrl}/api/monitoring/system-health`,
      'System Health Check'
    );
  }

  captureMemorySnapshot(): void {
    const memUsage = process.memoryUsage();
    this.metrics.memorySnapshots.push({
      timestamp: new Date(),
      heapUsed: memUsage.heapUsed,
      rss: memUsage.rss,
    });
  }

  async runHealthCheckCycle(): Promise<void> {
    logger.info('ğŸ”„ Running burn-in test cycle...');
    
    await Promise.all([
      this.checkQueueHealth(),
      this.checkAIModels(),
      this.checkSystemHealth(),
    ]);

    this.captureMemorySnapshot();
    this.printCurrentStatus();
  }

  printCurrentStatus(): void {
    const runtime = (Date.now() - this.metrics.startTime.getTime()) / 1000 / 60 / 60;
    const successRate = this.metrics.totalRequests > 0
      ? ((this.metrics.successfulRequests / this.metrics.totalRequests) * 100).toFixed(2)
      : '0';

    const latestMemory = this.metrics.memorySnapshots[this.metrics.memorySnapshots.length - 1];
    const memoryMB = latestMemory ? (latestMemory.heapUsed / 1024 / 1024).toFixed(2) : '0';

    logger.info(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           24-HOUR BURN-IN TEST - STATUS REPORT                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Runtime:          ${runtime.toFixed(2)} hours / 24 hours                  â•‘
â•‘ Total Requests:   ${this.metrics.totalRequests}                                      â•‘
â•‘ Success Rate:     ${successRate}%                                   â•‘
â•‘ Failed Requests:  ${this.metrics.failedRequests}                                      â•‘
â•‘ Memory Usage:     ${memoryMB} MB                                â•‘
â•‘                                                               â•‘
â•‘ Health Checks:                                                â•‘
â•‘   - Queue Health:    ${this.metrics.queueHealthChecks} checks                         â•‘
â•‘   - AI Models:       ${this.metrics.aiModelChecks} checks                         â•‘
â•‘   - System Health:   ${this.metrics.systemHealthChecks} checks                         â•‘
â•‘                                                               â•‘
â•‘ Recent Errors:    ${this.metrics.errors.slice(-3).length} (last 3 shown)              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `);

    if (this.metrics.errors.length > 0) {
      logger.warn('Recent errors:');
      this.metrics.errors.slice(-3).forEach((err) => {
        logger.warn(`  - [${err.timestamp.toISOString()}] ${err.error}`);
      });
    }
  }

  printFinalReport(): void {
    const totalRuntime = (Date.now() - this.metrics.startTime.getTime()) / 1000 / 60 / 60;
    const successRate = ((this.metrics.successfulRequests / this.metrics.totalRequests) * 100).toFixed(2);

    const memoryGrowth = this.analyzeMemoryGrowth();
    const queuePerformance = this.analyzeQueuePerformance();

    logger.info(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         24-HOUR BURN-IN TEST - FINAL REPORT                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Start Time:       ${this.metrics.startTime.toISOString()}       â•‘
â•‘ End Time:         ${new Date().toISOString()}       â•‘
â•‘ Total Runtime:    ${totalRuntime.toFixed(2)} hours                           â•‘
â•‘                                                               â•‘
â•‘ REQUEST STATISTICS:                                           â•‘
â•‘   Total Requests:     ${this.metrics.totalRequests}                              â•‘
â•‘   Successful:         ${this.metrics.successfulRequests} (${successRate}%)                    â•‘
â•‘   Failed:             ${this.metrics.failedRequests}                              â•‘
â•‘                                                               â•‘
â•‘ MEMORY ANALYSIS:                                              â•‘
â•‘   Initial Heap:       ${memoryGrowth.initial} MB                      â•‘
â•‘   Final Heap:         ${memoryGrowth.final} MB                      â•‘
â•‘   Growth:             ${memoryGrowth.growth} MB (${memoryGrowth.growthPercent}%)         â•‘
â•‘   Status:             ${memoryGrowth.status}                          â•‘
â•‘                                                               â•‘
â•‘ QUEUE PERFORMANCE:                                            â•‘
â•‘   Avg Redis Latency:  ${queuePerformance.avgLatency} ms                     â•‘
â•‘   Max Redis Latency:  ${queuePerformance.maxLatency} ms                     â•‘
â•‘   Total Failed Jobs:  ${queuePerformance.totalFailed}                              â•‘
â•‘   Status:             ${queuePerformance.status}                          â•‘
â•‘                                                               â•‘
â•‘ ERRORS ENCOUNTERED:   ${this.metrics.errors.length}                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `);

    if (this.metrics.errors.length > 0) {
      logger.warn('\nğŸ“‹ ERROR SUMMARY:');
      this.metrics.errors.forEach((err) => {
        logger.warn(`  - [${err.timestamp.toISOString()}] ${err.error}`);
      });
    }

    const verdict = this.getVerdict(successRate, memoryGrowth, queuePerformance);
    logger.info(`\n${verdict}`);
  }

  analyzeMemoryGrowth() {
    if (this.metrics.memorySnapshots.length === 0) {
      return { initial: 0, final: 0, growth: 0, growthPercent: '0.00', status: 'No data' };
    }

    const initial = this.metrics.memorySnapshots[0].heapUsed / 1024 / 1024;
    const final = this.metrics.memorySnapshots[this.metrics.memorySnapshots.length - 1].heapUsed / 1024 / 1024;
    const growth = final - initial;
    const growthPercent = ((growth / initial) * 100).toFixed(2);

    let status = 'âœ… HEALTHY';
    if (growth > 500) {
      status = 'âš ï¸ POTENTIAL LEAK';
    } else if (growth > 200) {
      status = 'âš ï¸ HIGH GROWTH';
    }

    return {
      initial: initial.toFixed(2),
      final: final.toFixed(2),
      growth: growth.toFixed(2),
      growthPercent,
      status,
    };
  }

  analyzeQueuePerformance() {
    if (this.metrics.queueMetrics.length === 0) {
      return { avgLatency: 0, maxLatency: 0, totalFailed: 0, status: 'No data' };
    }

    const latencies = this.metrics.queueMetrics.map(m => m.redisLatency);
    const avgLatency = (latencies.reduce((a, b) => a + b, 0) / latencies.length).toFixed(2);
    const maxLatency = Math.max(...latencies);
    const totalFailed = this.metrics.queueMetrics[this.metrics.queueMetrics.length - 1].failed;

    let status = 'âœ… HEALTHY';
    if (maxLatency > 100) {
      status = 'âš ï¸ HIGH LATENCY';
    } else if (totalFailed > 50) {
      status = 'âš ï¸ HIGH FAILURES';
    }

    return {
      avgLatency,
      maxLatency,
      totalFailed,
      status,
    };
  }

  getVerdict(successRate: string, memoryGrowth: any, queuePerformance: any): string {
    const rate = parseFloat(successRate);

    if (rate >= 99.9 && memoryGrowth.status === 'âœ… HEALTHY' && queuePerformance.status === 'âœ… HEALTHY') {
      return `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ… VERDICT: PASS                           â•‘
â•‘                                                               â•‘
â•‘  The platform successfully completed the 24-hour burn-in      â•‘
â•‘  test with excellent stability metrics. The system is         â•‘
â•‘  PRODUCTION-READY for paying customers.                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
    } else if (rate >= 95) {
      return `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 âš ï¸ VERDICT: CONDITIONAL PASS                  â•‘
â•‘                                                               â•‘
â•‘  The platform completed the burn-in test with minor issues.   â•‘
â•‘  Review warnings before production deployment.                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
    } else {
      return `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âŒ VERDICT: FAIL                           â•‘
â•‘                                                               â•‘
â•‘  The platform encountered significant issues during the       â•‘
â•‘  burn-in test. DO NOT deploy to production until resolved.    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
    }
  }

  async start(): Promise<void> {
    this.isRunning = true;
    logger.info(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        STARTING 24-HOUR BURN-IN TEST                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  This test will run for 24 hours, continuously monitoring:    â•‘
â•‘    - Queue health and Redis performance                       â•‘
â•‘    - AI model cache behavior                                  â•‘
â•‘    - System health metrics                                    â•‘
â•‘    - Memory usage trends                                      â•‘
â•‘                                                               â•‘
â•‘  Health checks will run every ${this.intervalMinutes} minutes.                   â•‘
â•‘                                                               â•‘
â•‘  Press Ctrl+C to stop the test early (not recommended).       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `);

    await this.runHealthCheckCycle();

    schedule(`*/${this.intervalMinutes} * * * *`, async () => {
      if (this.isRunning) {
        await this.runHealthCheckCycle();
      }
    });

    setTimeout(() => {
      this.stop();
    }, 24 * 60 * 60 * 1000);
  }

  stop(): void {
    this.isRunning = false;
    logger.info('ğŸ›‘ Stopping 24-hour burn-in test...');
    this.printFinalReport();
    process.exit(0);
  }
}

const burnInTest = new BurnInTest();

process.on('SIGINT', () => {
  logger.info('\nâš ï¸ Received interrupt signal...');
  burnInTest.stop();
});

burnInTest.start().catch((error) => {
  logger.error('Fatal error in burn-in test:', error);
  process.exit(1);
});
